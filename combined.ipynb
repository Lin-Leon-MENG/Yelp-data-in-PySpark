{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1579188846172_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-0-33.us-west-1.compute.internal:20888/proxy/application_1579188846172_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-9-249.us-west-1.compute.internal:8042/node/containerlogs/container_1579188846172_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import os\n",
    "import re\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e2c59a9a1740c492273527a3b308e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6a21889f2349faa85d47d2cc30af8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e0efd9021d455c970c1fa2b0e5a53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process business\n",
    "\n",
    "business = sc.textFile(\"s3n://usfca-distributedcomputing/yelp_business.csv\", 24)\n",
    "\n",
    "header = business.first()\n",
    "business = business.filter(lambda row: row != header)\n",
    "\n",
    "# Clean data before splitting\n",
    "business = business.map(lambda x: re.sub(',(?=[^\"]*\"[^\"]*(?:\"[^\"]*\"[^\"]*)*$)','', x))\n",
    "\n",
    "def toDoubleSafe(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except ValueError:\n",
    "        return str(v)\n",
    "\n",
    "business = business.map(lambda x: x.split(','))\n",
    "business = business.map(lambda row: [toDoubleSafe(x) for x in row])\n",
    "business.take(2)\n",
    "\n",
    "business_df = ss.createDataFrame(business)\n",
    "\n",
    "business_df.show(3)\n",
    "\n",
    "old_columns = business_df.schema.names\n",
    "new_columns = header.split(',')\n",
    "\n",
    "business_df = reduce(lambda data, idx: data.withColumnRenamed(old_columns[idx],\n",
    "                                                              new_columns[idx]),\n",
    "                     range(len(old_columns)), business_df)\n",
    "\n",
    "business_df.show(3)\n",
    "\n",
    "business_df.printSchema()\n",
    "\n",
    "# Filter and keep only restaurants that are opened\n",
    "restaurants_df = business_df.filter(business_df['categories'].contains('Restaurant')).filter(business_df['is_open']==1)\n",
    "restaurants_df.show(2)\n",
    "\n",
    "restaurants_df.count()\n",
    "\n",
    "# Keep only interesting variables\n",
    "restaurants_df = restaurants_df.select(\"business_id\", \"latitude\", \"longitude\", \"stars\", \"review_count\")\n",
    "restaurants_df.show(3)\n",
    "\n",
    "# No Null values\n",
    "print(restaurants_df.filter(restaurants_df.review_count.isNull()).count())\n",
    "print(restaurants_df.filter(restaurants_df.business_id.isNull()).count())\n",
    "print(restaurants_df.filter(restaurants_df.longitude.isNull()).count())\n",
    "print(restaurants_df.filter(restaurants_df.latitude.isNull()).count())\n",
    "print(restaurants_df.filter(restaurants_df.stars.isNull()).count())\n",
    "\n",
    "# Process business attributes\n",
    "\n",
    "attributes_df = ss.read.csv(\"s3n://usfca-distributedcomputing/yelp_business_attributes.csv\", header=True)\n",
    "\n",
    "attributes_df = attributes_df.select(\"BusinessAcceptsCreditCards\", \"BusinessParking_garage\",\n",
    "                                     \"BusinessParking_street\", \"BusinessParking_lot\",\n",
    "                                     \"BusinessParking_valet\", \"WheelchairAccessible\", \n",
    "                                     \"BikeParking\", \"Alcohol\", \"HappyHour\", \"OutdoorSeating\",\n",
    "                                     \"DogsAllowed\", \"business_id\")\n",
    "attributes_df.printSchema()\n",
    "\n",
    "# Create Parking boolean column if Car parking available\n",
    "attributes_df = attributes_df.withColumn(\"Parking\",\n",
    "                                         (attributes_df['BusinessParking_garage'] == 'True') | \n",
    "                                         (attributes_df['BusinessParking_street'] == 'True') |\n",
    "                                         (attributes_df['BusinessParking_lot'] == 'True') |\n",
    "                                         (attributes_df['BusinessParking_valet'] == 'True'))\n",
    "attributes_df = attributes_df.drop('BusinessParking_garage', 'BusinessParking_street',\n",
    "                                   'BusinessParking_lot', 'BusinessParking_valet')\n",
    "\n",
    "attributes_df.printSchema()\n",
    "\n",
    "# Create boolean values for all variables\n",
    "attributes_df = attributes_df.withColumn(\"Accepts_Credit_Cards\", \n",
    "                                         attributes_df['BusinessAcceptsCreditCards'] == 'True')\n",
    "attributes_df = attributes_df.withColumn(\"Wheelchair_Accessible\", \n",
    "                                         attributes_df['WheelchairAccessible'] == 'True')\n",
    "attributes_df = attributes_df.withColumn(\"Bike_Parking\", \n",
    "                                         attributes_df['BikeParking'] == 'True')\n",
    "attributes_df = attributes_df.withColumn(\"Alcohol_drinks\", \n",
    "                                         attributes_df['Alcohol'] == 'True')\n",
    "attributes_df = attributes_df.withColumn(\"Happy_Hour\", \n",
    "                                         attributes_df['HappyHour'] == 'True')\n",
    "attributes_df = attributes_df.withColumn(\"Outdoor_Seating\", \n",
    "                                         attributes_df['OutdoorSeating'] == 'True')\n",
    "attributes_df = attributes_df.withColumn(\"Dogs_Allowed\", \n",
    "                                         attributes_df['DogsAllowed'] == 'True')\n",
    "\n",
    "\n",
    "attributes_df = attributes_df.drop('BusinessAcceptsCreditCards', 'WheelchairAccessible', 'BikeParking',\n",
    "                                   'Alcohol', 'HappyHour', 'OutdoorSeating', 'DogsAllowed')\n",
    "\n",
    "attributes_df.printSchema()\n",
    "\n",
    "# Process Checkin\n",
    "\n",
    "checkin_df = ss.read.csv(\"s3n://usfca-distributedcomputing/yelp_checkin.csv\", inferSchema=True, header=True)\n",
    "checkin_df.show(5)\n",
    "checkin_df.printSchema()\n",
    "\n",
    "# check null\n",
    "print(checkin_df.where(checkin_df.business_id.isNull()).count())\n",
    "print(checkin_df.where(checkin_df.weekday.isNull()).count())\n",
    "print(checkin_df.where(checkin_df.hour.isNull()).count())\n",
    "print(checkin_df.where(checkin_df.checkins.isNull()).count())\n",
    "\n",
    "# counts of business_id, max 168 (7*24)\n",
    "id_ct = checkin_df.groupBy(\"business_id\").count().orderBy(\"count\", ascending=False)\n",
    "id_ct.show(10)\n",
    "\n",
    "# evenly distributed\n",
    "checkin_df.groupBy(\"weekday\").count().show()\n",
    "\n",
    "checkin_df.write.option(\"path\", \"s3n://usfca-distributedcomputing/checkin_df\").saveAsTable(\"checkin_df\")\n",
    "\n",
    "# keep ids with at least 7*8=56 occurences\n",
    "checkin_v1 = ss.sql(\"with checkin as (select * from parquet.`s3n://usfca-distributedcomputing/checkin_df`) \\\n",
    "                     , id_ct as (select business_id, count(*) as ct from checkin group by business_id having ct >= 56) \\\n",
    "                     select * from checkin where business_id in (select business_id from id_ct)\")\n",
    "print(checkin_v1.count())\n",
    "checkin_v1.show()\n",
    "\n",
    "def is_weekend(day):\n",
    "    if day in [\"Sat\", \"Sun\"]:\n",
    "        return \"Weekend\"\n",
    "    else:\n",
    "        return \"Weekday\"\n",
    "    \n",
    "check_is_weekend = udf(is_weekend)\n",
    "\n",
    "# flag weekend\n",
    "checkin_v1 = checkin_v1.select([\"business_id\", \"hour\", \"checkins\", \"weekday\", check_is_weekend(\"weekday\")])\n",
    "checkin_v1 = checkin_v1.withColumnRenamed(\"is_weekend(weekday)\", \"weekend\")\n",
    "checkin_v1.show(3)\n",
    "\n",
    "# average hourly checkin numbers\n",
    "avg_hourly_checkin = checkin_v1.groupBy([\"business_id\"]).pivot(\"weekend\").agg(avg(\"checkins\"))\n",
    "print(avg_hourly_checkin.count())\n",
    "avg_hourly_checkin.show(5)\n",
    "\n",
    "# Join the data\n",
    "\n",
    "# Left_outer join\n",
    "joined_df = restaurants_df.join(attributes_df, 'business_id', 'left_outer')\n",
    "\n",
    "joined_df.show(2)\n",
    "\n",
    "joined_df.printSchema()\n",
    "\n",
    "# We had some restaurant from business table not in business_attributes\n",
    "# Need to treat the null values\n",
    "joined_df.groupBy(joined_df[\"Parking\"]).count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Replace null values by false (most common value)\n",
    "joined_df = joined_df.na.fill(False)\n",
    "\n",
    "joined_df.groupBy(joined_df[\"Parking\"]).count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "joined_df = joined_df.join(avg_hourly_checkin, 'business_id')\n",
    "\n",
    "sentiment_df = ss.read.csv(\"s3n://usfca-distributedcomputing/sentiment\")\n",
    "old_cols = sentiment_df.schema.names\n",
    "new_cols = ['business_id','avg_sentiment']\n",
    "\n",
    "sentiment_df = reduce(lambda data, idx: data.withColumnRenamed(old_cols[idx],\n",
    "                                                              new_cols[idx]),\n",
    "                     range(len(old_cols)), sentiment_df)\n",
    "\n",
    "joined_df = joined_df.join(sentiment_df, \"business_id\", how=\"left_outer\")\n",
    "print(f\"Nulls (avg_sentiment): {joined_df.where(joined_df.avg_sentiment.isNull()).count()}\")\n",
    "\n",
    "joined_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989f9946681a4309a8a102631f47cc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------+-----+------------+-------+--------------------+---------------------+------------+--------------+----------+---------------+------------+------------------+------------------+-------------------+\n",
      "|         business_id|     latitude|     longitude|stars|review_count|Parking|Accepts_Credit_Cards|Wheelchair_Accessible|Bike_Parking|Alcohol_drinks|Happy_Hour|Outdoor_Seating|Dogs_Allowed|           Weekday|           Weekend|      avg_sentiment|\n",
      "+--------------------+-------------+--------------+-----+------------+-------+--------------------+---------------------+------------+--------------+----------+---------------+------------+------------------+------------------+-------------------+\n",
      "|-d0Ou1JmEK2j5HR4P...|36.0166853346|-114.958591805|  3.0|        32.0|   true|               false|                false|       false|         false|     false|          false|       false|1.6590909090909092|2.8461538461538463|        0.509015625|\n",
      "|-sNi7U9seVfCr8T8n...|    33.380569|  -111.7545927|  4.0|       101.0|   true|               false|                false|        true|         false|     false|          false|       false|3.8653846153846154| 6.458333333333333| 0.6855227722772277|\n",
      "|1M0Mo_ctYMTH0CTKg...|   33.3776606|    -112.16893|  3.0|        36.0|  false|               false|                false|       false|         false|     false|          false|       false|              2.88|              2.75|0.28895555555555563|\n",
      "+--------------------+-------------+--------------+-----+------------+-------+--------------------+---------------------+------------+--------------+----------+---------------+------------+------------------+------------------+-------------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "# Save data\n",
    "\n",
    "joined_df.write.option(\"path\", \"s3n://usfca-distributedcomputing/yelp_data\").saveAsTable('yelp_data')\n",
    "\n",
    "# Read data\n",
    "\n",
    "ss.sql(\"select * from parquet.`s3n://usfca-distributedcomputing/yelp_data`\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
